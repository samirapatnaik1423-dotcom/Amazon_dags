# Amazon_dags
**Project Overview**
This project demonstrates an end-to-end data engineering pipeline implemented using Apache Airflow.
It covers data ingestion, validation, data quality checks, schema management, Bronze–Silver–Gold architecture, scheduling, metadata management, and data lineage following industry-standard practices.
The pipeline processes Amazon order data from multiple sources, ensures schema consistency and data quality, and produces analytics-ready outputs with full traceability.
Technology Stack

Apache Airflow – Workflow orchestration and scheduling

Python – ETL and validation logic

Pandas – Data processing

Pydantic – Schema validation

CSV / Parquet – Storage formats

JSON – Metadata, data quality, and lineage reports
