#!/bin/bash

# ETL Pipeline Health Check
# This script verifies all services are running correctly

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘         ğŸ¥ ETL Pipeline Health Check                       â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# Color codes
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Check Docker
echo -e "\n${BLUE}1. Checking Docker...${NC}"
if command -v docker &> /dev/null; then
    echo -e "${GREEN}âœ“ Docker is installed${NC}"
else
    echo -e "${RED}âœ— Docker is not installed${NC}"
    exit 1
fi

# Check PostgreSQL
echo -e "\n${BLUE}2. Checking PostgreSQL...${NC}"
if docker exec docker-postgres-1 pg_isready -U airflow -d airflow &> /dev/null; then
    echo -e "${GREEN}âœ“ PostgreSQL is running and healthy${NC}"
    
    # Check tables
    TABLES=$(docker exec docker-postgres-1 psql -U airflow -d airflow -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'etl'")
    echo -e "${GREEN}  â””â”€ ETL schema has $TABLES tables${NC}"
else
    echo -e "${RED}âœ— PostgreSQL is not responding${NC}"
fi

# Check Redis
echo -e "\n${BLUE}3. Checking Redis...${NC}"
if docker exec docker-redis-1 redis-cli ping &> /dev/null; then
    echo -e "${GREEN}âœ“ Redis is running${NC}"
else
    echo -e "${RED}âœ— Redis is not responding${NC}"
fi

# Check Airflow Webserver
echo -e "\n${BLUE}4. Checking Airflow Webserver...${NC}"
if curl -s http://localhost:8080/health | grep -q "healthy"; then
    echo -e "${GREEN}âœ“ Airflow Webserver is running and healthy${NC}"
else
    echo -e "${YELLOW}âš  Airflow Webserver is running but health check returned unexpected result${NC}"
fi

# Check Airflow Scheduler
echo -e "\n${BLUE}5. Checking Airflow Scheduler...${NC}"
if docker exec docker-scheduler-1 ps aux | grep -q "[s]cheduler"; then
    echo -e "${GREEN}âœ“ Airflow Scheduler is running${NC}"
else
    echo -e "${RED}âœ— Airflow Scheduler is not running${NC}"
fi

# Check DAGs
echo -e "\n${BLUE}6. Checking DAGs...${NC}"
DAG_COUNT=$(docker exec docker-scheduler-1 airflow dags list 2>/dev/null | grep -c "^\|" || echo "0")
if [ "$DAG_COUNT" -ge 3 ]; then
    echo -e "${GREEN}âœ“ DAGs are loaded in Airflow${NC}"
    docker exec docker-scheduler-1 airflow dags list 2>/dev/null | grep -E "customer_etl_dag|sales_etl_dag|unified_etl_dag" | while read line; do
        echo -e "${GREEN}  â””â”€ $line${NC}"
    done
else
    echo -e "${YELLOW}âš  DAGs may not be loaded yet, please wait...${NC}"
fi

# Summary
echo -e "\n${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo -e "${GREEN}âœ“ All services are operational!${NC}"
echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"

echo -e "\n${BLUE}ğŸ“Š Quick Stats:${NC}"
docker ps --format "table {{.Names}}\t{{.Status}}" | grep docker-

echo -e "\n${BLUE}ğŸŒ Access Points:${NC}"
echo -e "  ${YELLOW}Airflow UI:${NC}     http://localhost:8080 (admin/admin)"
echo -e "  ${YELLOW}PostgreSQL:${NC}    localhost:5432 (airflow/airflow)"
echo -e "  ${YELLOW}Redis:${NC}         localhost:6379"

echo -e "\n${BLUE}ğŸ“ Next Steps:${NC}"
echo -e "  1. Open http://localhost:8080 in your browser"
echo -e "  2. Login with admin / admin"
echo -e "  3. Find 'unified_etl_dag' and trigger it"
echo -e "  4. Monitor execution in real-time"

echo -e "\n${GREEN}âœ¨ Pipeline is ready for use!${NC}\n"
